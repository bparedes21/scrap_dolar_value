name: Web Scraping Automation

on:
    schedule:
      - cron: '0 12 * * *'  # Se ejecuta a las 12:00 UTC
      - cron: '0 13 * * *'  # Se ejecuta a las 13:00 UTC
      - cron: '0 14 * * *'  # Se ejecuta a las 14:00 UTC
      - cron: '0 15 * * *'  # Se ejecuta a las 15:00 UTC
      - cron: '0 16 * * *'  # Se ejecuta a las 16:00 UTC
      - cron: '0 17 * * *'  # Se ejecuta a las 17:00 UTC
      - cron: '0 18 * * *'  # Se ejecuta a las 18:00 UTC
      - cron: '0 19 * * *'  # Se ejecuta a las 19:00 UTC
      - cron: '0 20 * * *'  # Se ejecuta a las 20:00 UTC
      - cron: '0 21 * * *'  # Se ejecuta a las 21:00 UTC
jobs:
  scraping_job:
    runs-on: ubuntu-latest

    steps:
    - name: 🛠️ Configurar repositorio
      uses: actions/checkout@v3

    - name: 📦 Configurar Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: 📚 Instalar dependencias
      run: |
        python -m pip install --upgrade pip
        pip install playwright
        python -m playwright install

    - name: 🚀 Ejecutar script de scraping
      run: |
        python script.py

    - name: 📁 Subir archivo JSON como artefacto
      uses: actions/upload-artifact@v4
      with:
        name: dolar_data
        path: dolar_data.json 
    
    - name: ⚙️ Configurar git
      run: |
        git config --global user.name "bparedes21"
        git config --global user.email "gestionorganizacion17@gmail.com"

    - name: 📂 Añadir el archivo y hacer commit
      run: |
        git add dolar_data.json
        git commit -m "Guardar archivo de datos dolar_data.json" || echo "No hay cambios para hacer commit"
    
    - name: 🚀 Hacer push de los cambios
      env:
        GH_PAT: ${{ secrets.ADD_DATA }}
      run: |
        git push https://x-access-token:${{ secrets.ADD_DATA }}@github.com/bparedes21/scrap_dolar_value.git HEAD:main
